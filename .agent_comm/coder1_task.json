{
  "agent_id": "coder1",
  "task_id": "task_0",
  "files": [
    {
      "filename": "model_architecture.py",
      "purpose": "Defines the neural network architecture, including the Vision Transformer-based encoder and decoder.",
      "priority": "high",
      "dependencies": [
        "torch",
        "transformers"
      ],
      "key_functions": [
        "__init__",
        "forward",
        "build_transformer_block"
      ],
      "estimated_lines": 400,
      "complexity": "high"
    }
  ],
  "project_info": {
    "project_name": "Spatiodynamic Inference using Vision-Based Generative Modeling",
    "project_type": "computer_vision",
    "description": "This project implements a simulation-based inference framework that employs vision transformer-driven variational encoding to generate compact representations of spatiotemporal data, exploiting inherent contextual dependencies for parameter inference in multivariate dynamical systems.",
    "key_algorithms": [
      "Variational Autoencoder (VAE)",
      "Vision Transformer (ViT)",
      "Approximate Bayesian Computation (ABC)",
      "Sequential Monte Carlo (SMC)"
    ],
    "main_libraries": [
      "torch",
      "transformers",
      "numpy",
      "pandas",
      "scikit-learn"
    ]
  },
  "paper_content": "PDF: stat.ML_2507.22256v1_Spatiodynamic-inference-using-vision-based-generat.pdf\nChunk: 1/1\n==================================================\n\n--- Page 1 ---\nSpatiodynamic Inference Using Vision-Based\nGenerative Modeling\nJun Won Park, Kangyu Zhao, Sanket Rane *\nIrving Institute for Cancer Dynamics, Columbia University, New York, USA\nAbstract\nBiological systems commonly exhibit complex spatiotemporal patterns whose underlying\ngenerative mechanisms pose a significant analytical challenge. Traditional approaches to spa-\ntiodynamic inference rely on dimensionality reduction through summary statistics, which sac-\nrifice complexity and interdependent structure intrinsic to these data in favor of parameter\nidentifiability. This imposes a fundamental constraint on reliably extracting mechanistic in-\nsights from spatiotemporal data, highlighting the need for analytical frameworks that preserve\nthe full richness of these dynamical systems. To address this, we developed a simulation-based\ninference framework that employs vision transformer-driven variational encoding to generate\ncompact representations of the data, exploiting the inherent contextual dependencies. These\nrepresentations are subsequently integrated into a likelihood-free Bayesian approach for pa-\nrameter inference. The central idea is to construct a fine-grained, structured mesh of latent rep-\nresentations from simulated dynamics through systematic exploration of the parameter space.\nThis encoded mesh of latent embeddings then serves as a reference map for retrieving parame-\nter values that correspond to observed data. By integrating generative modeling with Bayesian\nprinciples, our approach provides a unified inference framework to identify both spatial and\ntemporal patterns that manifest in multivariate dynamical systems.\n*Corresponding Author: sanket.rane@columbia.edu\n1arXiv:2507.22256v1  [q-bio.QM]  29 Jul 2025\n\n--- Page 2 ---\nIntroduction\nSpatiotemporal patterns are ubiquitous in biological systems whose mechanistic underpinnings\npresent a significant analytical challenge. Spatial dynamical data exhibit multi-scale dependen-\ncies among observed variables, encompassing both local and global relationships. Mathematical\nmodels are a natural language for describing such interconnectedness and for inferring causal re-\nlationships. However, the accuracy of their conclusions hinges on precisely identifying model pa-\nrameters (\u03b8)and quantifying the uncertainty in their estimation using the observed data (y).\nIn Bayesian regimes, this involves determining the posterior distribution \u03c0(\u03b8|y)given the prior\n\u03c0(\u03b8)and the likelihood function p(y|\u03b8). In cases where traditional likelihood-based methods are\nimpractical, approximate Bayesian Computation (ABC) offers an appealing solution to estimating\nposterior using simulated data1\u20133. ABC and its modern variants4\u20137use a distance metric , \u03c1(\u00b7), to\ngauge the similarity between simulated and observed datasets and a threshold \u03f5to accept poste-\nrior samples ( eq. 1 ), such that, as \u03f5\u21920, ABC posterior approaches the Bayesian posterior.\n\u03c0(\u03b8|Y=yobs)\u2248\u03c0(\u03b8|\u03c1(ysim, yobs)\u2264\u03f5) (1)\nInference on spatial data typically involves mixed models, consisting a regression model for co-\nvariates and a random-effects model, such as the Gaussian process, for spatial dependence8\u201313.\nIn many studies, specifically in epidemiology, summarized statistics are leveraged to estimate\nmodel parameters using Bayesian methods14\u201316. Formulating meaningful summary statistics be-\ncomes increasingly difficult when working with high-dimensional spaces, frequently resulting in\nill-posed inverse problems where parameter identifiability is compromised. These factors criti-\ncally impede reliable mechanistic inference on spatiotemporal dynamics, highlighting the need\nfor more sophisticated approaches that preserve the full richness of these data.\nTo bridge this gap, we defined an integrative approach that combines a generative deep learning\nmodel with ABC to infer the underlying data-generating process and assess uncertainty in its\nparameter estimation. We begin with a simple hypothesis that complex observed data contain\nunderlying simpler patterns that are unobserved. These hidden patterns can yield significant\ninsights regarding the parameters that govern dynamical or mechanistic variations within the\ndata. Our objective is to construct a structured mesh of latent representations of simulated data\nby systematically drawing samples from the prior. This reference map will then be employed in a\nBayesian framework to extract model parameters corresponding to the actual observations.\nWe developed a variational inference-assisted ABC (viaABC) framework by integrating elements\nof Vision Transformer (ViT) and variational autoencoding (VAE) to construct the reference map\nof latent representations. viaABC begins with a self-supervised training phase on synthetic data\ngenerated using parameter samples drawn from model-agnostic, weakly informative priors. The\ntrained encoder is integrated into a simulation-based inference framework to systematically com-\n2\n\n--- Page 3 ---\npare the latent representations of observed data with those generated from simulations of the\nmechanistic model ( eq. 2 ) using an adaptive acceptance criterion17. Through this process, viaABC\napproximates the posterior distribution of the parameters that underlie the observed dynam-\nics,\n\u03c0(\u03b8|y=yobs)\u2248\u03c0(\u03b8|\u03c1(\u03b6(ysim), \u03b6(yobs))\u2264\u03f5), (2)\nwhere \u03b6(\u00b7)represents variational encoding process that generates the latent variables.\nToy example: The spatial SIRS model\nInfectious disease spread is characterized by complex spatiotemporal patterns18\u201320, which can be\nmodeled through spatial adaptations of the susceptible-infected-recovered (SIR) model21. To as-\nsess latent-ABC\u2019s ability to conduct mechanistic inference on spatial dynamical data, we employed\na grid-structured contact network spatial SIR model as developed by van Ballegooijen et al.22. This\nframework utilized a modification of the classical SIR, known as the SIRS model23, in which indi-\nviduals occupy one of three states: susceptible (S), infected (I), or resistant (R) ( Fig. 1A ).\nInfection neighborhoodS I R\u03b2 \u03c4I\u03c4RTime A BInfection rate (\u03b2)\nC Time\nSpatial time series  Yt Slices from a same simulation to generate\nFigure 1: Spatial dynamics of the SIRS model .A.Schematic of the state transitions. In addition, we depict the contact-\ngrid for each individual (pixel), which serves as the infection neighborhood. B.An illustration of the varied patterns\ngenerated by the SIRS model. This particular example depicts the output of SIRS model at times t= 4,8,12,16(left\nto right) by fixing \u03c4I=\u03c4R= 1 and varying \u03b2= 0.4,0.7,1.0,2.0(top to bottom). Such diversity allows us to train the\ndeep learning model on a wide assortment of spatiotemporal patterns, which we generate by sampling \u03b8from a model\nagnostic prior distribution. C.Schematic of data generation and processing . We simulate the SIRS model using the\ntime-step of 0.05and slice the generated video at every 20th step to construct the spatial time series.\nWithin this model, infected individuals stochastically transmit the infection to neighboring sus-\nceptible individuals at the rate \u03b2. The infection neighborhood is represented by eight adjacent\nindividuals on a square lattice ( Fig. 1A ). The duration of the infectious period is fixed at \u03c4I, fol-\nlowing which the infected individuals transition to the resistant state. Subsequently, resistant\nindividuals revert to the susceptible state after a fixed time period \u03c4R. We adhered to the method-\nology outlined in van Ballegooijen et al.22, scale \u03c4Rto unity and sought to infer \u03b8= (\u03b2, \u03c4I), using\nour framework. The SIRS model produces well-defined spatiotemporal patterns\u2014from scattered\nclusters to infection waves\u2014that are clearly delineated by its parameters ( Fig. 1B ) and, as such,\nprovides an excellent test case for evaluating viaABC\u2019s performance. We generated a synthetic\n3\n\n--- Page 4 ---\ndataset by fixing \u03b8= (1.0,1.0)as the ground truth. We sampled 15 slices of images from this\ndataset to create a test dataset (schematic shown in Fig. 1B ), which we refer to as the \u2018observed\ndata\u2019 ( yobs). We generated the training data for VAE similarly (see methods for details).\nCosine similarity of the latent variables as an acceptance criterion\nWe postulate that contextual relationship between data points and patterns hidden within the\ndata generating processes could be realized by projecting simulations and observed data to latent\nvariables. Such projections could precisely inform on model parameters and may also help in\nmodel validation and selection procedures. To facilitate this we propose to use closeness between\nlatent variables of the observed and simulated data, which we evaluate using patch-wise cosine\nsimilarity, as an acceptance criterion ( Fig. 2 ).\nEncoder\n Decoder\nVisible \nTokenEncoded \nTokenMasked \nToken\nTokens w/o masking\nMathematical \nmodelPrior\n\u03b8i ~ P(\u03b8)\nSimulated Data\nObserved DataShared WeightsPatch-wise Cosine \nSimilarity\nAccept\nRejectPosterior\n< \u03b5Simulated slices\nTime\nMaskingTime\nReconstructed slicesTimeA\nB Time\nEncoder\nEncoder\nMean\u2265 \u03b5\nFigure 2: Schematic of the viaABC framework . We depict viaABC operation for spatial dynamical data relevant to\nthe SIRS model. A. Training: Each training sample consists of a sequence of simulated images or data slices. Each slice\nis divided into multiple non-overlapping regions called patches. We group patches along the time dimension to form\ncubes, which are then flattened into vectorized representation called tokens. Within each training sample, a random\nsubset of tokens is masked. VAE is trained to reconstruct the original data using tokens as the input, while minimizing\nthe KL divergence loss in the latent space. Encoder is applied to only visible tokens (purple). Encoded tokens (blue) are\nprobabilistically sampled and along with the mask tokens (gray) are then processed by a decoder. B. Inference: Trained\nencoder is applied to the unmasked data, both simulated and observed, to infer model parameters using sequential\nMonte Carlo and patch-wise cosine similarity as an acceptance criterion. We exclude the decoder and sampling process\nfrom the inference procedure. Principles of training and inference remain same across all data types and architectures\ndescribed in this study.\n4\n\n--- Page 5 ---\nWe customized a VAE model by adopting the transformer-based masked autoencoder24and im-\nposing a probability distribution in the latent space via Kullback\u2013Leibler (KL) divergence. The\nresultant loss function is,\nL=Lrecon+\u03bbLKL, (3)\nwhere Lrecon is the reconstruction loss, LKLdenotes the KL divergence loss. The hyperparameter\n\u03bbmediates the trade-off between Lrecon andLKL25. Our approach considers the loss in recon-\nstruction for both unmasked and masked patches, deviating from conventional masked modeling\napproaches that only rely on masked patches.26\u201328. In addition, we only use the encoded tokens\nto calculate the KL divergence loss ( Fig. 2A ).\nTo generate the training data we draw Nparameter sets from a joint prior distribution using Latin\nhypercube sampling (LHS). We chose LHS as it provides a thorough exploration of the parameter\nspace resulting in a diverse range of parameter configurations29. Further, we use wide uniform\npriors for the training procedure to mitigate the risk of overfitting to specific modes in the param-\neter space. Given a mathematical model or data-generating process f, this procedure yields N\npairs of {(\u03b8i, f(\u03b8i))}N\ni=1. Masked VAE is trained on {f(\u03b8i)}N\ni=1to reconstruct the input data while\nminimizing the total loss L(Fig. 2A ).\nWe define ABC posterior following the notations of Marin et al.30and Simola et al.17as,\n\u03c0\u03f5(\u03b8|yobs) =Z\u0014p(ysim|\u03b8)\u03c0(\u03b8) 1A\u03f5,yobs(ysim)\nR\nA\u03f5,yobs\u00d7\u0398p(y|\u03b8)\u03c0(\u03b8)dysimd\u03b8\u0015\ndysim,\nwhere 1A\u03f5,yobs(\u00b7)is the indicator function for the set A\u03f5,yobs={ysim|\u03c1(s(yobs), s(ysim))\u2264\u03f5},\n\u03c1(\u00b7,\u00b7)is the distance function and s(\u00b7)is the summary statistic function.\nIn viaABC, we modify the set notation such that,\nA\u03f5,yobs={ysim|\u03c1(zobs, zsim)\u2264\u03f5},\nwhere zobsandzsimare latent embeddings of the observed and simulated data outputted by the\ncombination of the encoder and re-parameterization layers. The re-parameterization layer im-\nposes a standard Gaussian distribution in the latent space through,\nZ=\u00b5+\u03c3\u03f5, \u03f5 \u223c N(0, I), (4)\nwhich then outputs mean \u00b5iand standard deviation \u03c3ivectors for each token i. Both the decoder\nand sampling process are excluded from the inference procedure and only the vector of means\n\u00b5is considered ( Fig. 2B ) such that the latent representation Z=\u00b5(eq. 4 ). We use patch-wise\ncosine distance metric to compute the distance between latent embeddings ( Algorithm 1 Line 6 ),\n(Fig. 2B ). For each pair of corresponding patches in zobsandzsim, we compute cosine similarity\n5\n\n--- Page 6 ---\nand aggregate across all npatches such that\n\u03c1(zsim, zobs) = 1\u2212nX\ni=1zobs\ni\u00b7zsim\ni\n||zobs\ni||2||zsim\ni||2(5)\nwhere Z\u2208Rn\u00d7E, where Eis the embedding dimension of the decoder. Sampled parameters are\naccepted based on the patch-wise cosine distance metric ( eq. 5 ).\nParameter inference from learned representations of spatiotemporal input\nB\nObserved Inferred Observed Inferred Observed InferredC\u03b2Proportion\nProportion\u03c4I\n\u03bb values0.000 0.001 0.010 0.100Parameter estimates \n0.80.91.01.11.2\n1.030\n0.9171.0400.982 1.0061.061\n1.0181.060\u03b2  \u03c4I\nMean \u00b1 std. dev.\nSusceptible Infected Resistant\nTime\nFraction of totalSusceptible \nInfected \nResistant Predicted SIR dynamics D0.85 0.90 0.95 1.00 1.05 1.10 1.150.91.01.11.21.30.85 0.90 0.95 1.00 1.05 1.10 1.150.000.020.040.060.080.10\n0.00 0.05 0.100.91.01.11.21.3\n0 2 4 6 8 10 12 140.00.20.40.60.81.0\nA\nFigure 3: Posterior inference on spatial SIRS dynamics using viaABC .A.Kernel density estimate of the final particles\nfor the parameters \u03b2and\u03c4I.B.Comparison of spatiotemporal dynamics of the observed data and predictions generated\nusing the mean parameter estimates. Predictions were initialized within the similar region on the spatial grid as that of\nthe observed data (see Methods for details). C.SIRS dynamics aggregated across spatial dimensions. We average the\nproportions of S, I, and R at each time point across 10 simulations generated from each posterior draw. Dots represent\nobserved data. Lines denote the mean of predictions, and envelopes are 95% credible intervals. D.Mean estimates\nand corresponding standard deviations, calculated from five independent experiments for each \u03bbvalue. Results from\nViT-VAE trained with \u03bb= 0.1are highlighted in yellow. Dashed line represent the ground truth. Note that \u03bb= 0\ncorresponds to the standard MAE.\nWe employed viaABC to estimate the parameters ( \u03b8= (\u03b2, \u03c4I)) of the spatial SIRS model using\nsynthetically generated observed data ( Fig. 1C ). We sampled \u03b2and\u03c4Ifrom a bivariate Unif (0,4.2)\nusing LHS and generated 50,000 simulations for training and an additional 10,000 simulations for\nvalidation. Each simulation contains 15 time points, with each time point representing a tensor\n6\n\n--- Page 7 ---\nof dimension 3\u00d780\u00d780. Here 80\u00d780denotes the spatial grid and the first dimension encodes\nthe state of each individual. The three channels reflect distinct states\u2014susceptible, infected, or\nresistant\u2014encoded in a binary format; for instance, each individual is denoted by a 1 in the second\nchannel if infected, otherwise 0. As the datatype only contained discrete labels, we formulated the\nreconstruction loss as cross-entropy loss.\nThe VAE architecture comprised a ViT based encoder with 6 layers and an embedding dimension\nof 128, and a smaller ViT based decoder with 4 layers and an embedding dimension of 64. The\ninput data of size 3\u00d715\u00d780\u00d780is divided into non-overlapping spatio-temporal cubes of size\n3\u00d73\u00d710\u00d710, yielding 500 cubes. Each cube is flattened to form a token, 15% of which are\nrandomly masked during training (as depicted in Fig. 2B ). We set \u03bb= 0.1ineq. 3 to calculate\nthe loss and train the VAE. We used the trained encoder and same prior as before to perform the\nposterior inference. viaABC iteratively and adaptively accepted 1,000 independent particles until\nthe stopping rule of qt= 0.99ort\u226520was satisfied (as described in Algorithm 1 ).\nThe posterior inferred through viaABC contained the ground truth, and the estimated mean \u02c6\u03b8\u2248\n(1.04,0.98)nearly coincided with \u03b8= (1,1)(Fig. 3A andD). Consistent with this, the predicted\nspatial SIR dynamics, generated using the mean of the posterior, closely mirrored the observed\ndata ( Fig. 3B ). We further show that the summarized SIRS dynamics generated using posterior\ndraws nicely captured the summary statistics of the observed data ( Fig. 3C ). Lastly, we explored\nthe effects of varying \u03bbon accuracy of the posterior inference. We present the aggregated results\nacross five independent experiments in ( Fig. 3B ). For all configurations, the 95% highest density\ninterval (HDI) from the posterior inference included the ground truth, suggesting that viABC\nis rather weakly sensitive to fluctuations in the regularization parameter \u03bb. Notably, all VAE\nconfigurations improved on the results from the autoencoder version ( Fig. 3D ) and, on average,\nconverged more efficiently, indicating a more structured latent space.\nInference on noisy dynamical input\nNext, we assessed and compared the efficacy of the viaABC algorithm in a non-spatial setting. We\nused the Lotka-Volterra model31 32, a classic system in ecology, which deterministically describes\nthe population dynamics and interactions between a prey (x)and predator (y)species. This sys-\ntem is expressed as a pair of nonlinear differential equations,\ndx\ndt=ax\u2212cxy,dy\ndt=bxy\u2212dy, (6)\nwhere aandbdenote rates of population growth of the prey and their per capita loss due to\npredation. Parameters canddrepresent the efficiency with which consumed prey are converted\ninto predator offspring and loss of the predators, respectively. The Lotka-Volterra model is a\nwell-studied system, and its parameters have been estimated using various methods, including\nABC6,33, ABC with distributional Random Forest (ABC-DRF)34, and ABC with deep learning\n7\n\n--- Page 8 ---\n(ABC-DL)35\u201337. We adhered to the methodology outlined in Toni6and Dinh34et al., fixed pa-\nrameters c=d= 1and sought to infer \u03b8= (a, b)using the prior a, b\u223cUniform (0,10).\nWe generated N= 50 ,000training simulations and 20,000validation samples of prey, preda-\ntor dynamics (shown as lines in Fig. 4A ), by sampling \u03b8from the joint prior distribution us-\ning LHS. We selected eight time points between t= 0 and15to represent our training data\nstrain={{xi\n1, yi\n1, . . . , xi\n8, yi\n8}}N\ni=1. The input data of size 2\u00d78is divided into 8 non-overlapping\npatches of size 2\u00d71. We trained the ViT-VAE using a masking ratio of 15%. The comparison be-\ntween reconstructions of masked and unmasked training data shows that our ViT-VAE effectively\nimputes missing observations using the patterns within the training data ( Fig. S1 ).\nFigure 4: Learning and inferring predator-prey dynamics .A.The simulated dynamics of the training data, denoted\nas lines, and the observed data, denoted as dots. Y-axis is on the log scale to fully visualize the wide range of predator-\nprey dynamics in the simulated data. B.ViT-VAE\u2019s reconstructions (lines) of the noisy observed data (dots). C.The\nkernel density estimated 2D heatmap of the final posteriors along with their histograms. The ground truth is denoted\nas dotted red lines. The estimated 95% HDI for a, bare (0.951, 1.188) and (0.768, 1.352), respectively. D.The 95% credible\nintervals of the predictions of prey, predator dynamics with medians as solid lines. Black dashed lines denote predator-\nprey dynamics generated using the ground truth without the Gaussian noise.\nTo construct the observed data, we evaluated x, y using eq. 6 at the same eight time points as\nthe training samples and by setting ( \u03b8= (1,1), see methods for details). Gaussian noise \u03f5t\u223c\nN(0,0.52)was added to this time series to represent experimental variation typically associated\nwith biological samples. This forms our noisy dynamical input sobs={xo\n1, yo\n1, . . . , xo\n8, yo\n8}(shown\nas dots in Fig. 4A ), which we used as the observed data for simulation-based inference. In Fig. 4B ,\nwe show the reconstruction of the sobs(original data as dots, reconstructed as lines).\n8\n\n--- Page 9 ---\nTo generate simulated data for parameter inference, we sampled \u03b8from the bivariate uniform\nprior to simulate time series ssim={xs\n1, ys\n1, . . . , xs\n8, ys\n8}. Both, observed simulated data are then\nencoded into their respective latent variables and were used to infer posterior of \u03b8using viaABC.\nSpecifically, We accepted 1,000 particles based on the cosine similarity of zsimtozobs. This proce-\ndure is repeated until the stopping rule described in the Algorithm 1 is satisfied.\nWe observed that the ground truth \u03b8= (1,1)lied within the high density region of the poste-\nrior of the accepted particles, very close to the estimated \u02c6\u03b8\u2248(1.06,1.06)(Fig. 4C ). We further\nshow that the 95% credible intervals of the predictions of prey, predator dynamics contains the\ndata generated using the ground truth and the median of the interval closely overlaps with the\nobserved data (Fig. 4D ). Lastly, we benchmarked our approach against other Monte Carlo-based\napproaches and found that viaABC delivered results comparable to well-known Bayesian algo-\nrithms ( Table 1 ) and produced lowest uncertainty in parameter estimation.\nStatistics viaABC MCMC ABC-SMC-DRF ABC-SMC\nE(a) 1.064 1.087 1.121 1.291\nVar(a) 0.005 0.006 0.033 0.110\nE(b) 1.057 1.100 0.970 1.026\nVar(b) 0.029 0.034 0.031 0.104\nTable 1: Means and variances of marginal posterior distributions of the parameters of the Lotka-Volterra model. We\ncompared the estimates obtained using viaABC with Markov Chain Monte Carlo (MCMC) sampler (produced using\nstan programming language and same priors, results shown in ( Fig. S2 ), ABC-SMC and ABC-SMC-DRF (results directly\ntaken from Dinh et al34). Expectations closest to the ground truth and lowest variances are highlighted in bold.\nDiscussion\nIn this study we introduced viaABC, a simulation-based inference framework that uses contex-\ntual dependencies inherent in the data to estimate parameters of multivariate dynamical systems.\nThe framework employs a vision transformer-based masked variational autoencoder to create or-\ndered latent representations of model simulations, where simulations with similar dynamics are\npositioned close together in the embedding space. The key insight is that by systematically explor-\ning the parameter space, viaABC builds a comprehensive reference library of simulated dynamics\nthat helps to identify which parameters most likely generated the patterns we see in the observed\ndata. We demonstrated efficacy of this approach using the spatial stochastic SIRS system, which\nexhibits complex dependencies between spatial dimensions and across time, where viaABC accu-\nrately retrieved model parameters and quantified the uncertainty in their estimation.\nVariational encoding confers viaABC the ability to accommodate datasets with diverse structures\nand dimensions, as VAE can be employed to compress or expand data dimensions as needed\nfor parameter inference. This can significantly reduce the computational burden typically asso-\nciated with large data structures, making viaABC aptly suitable for multidimensional data. For\ninstance, calculating the likelihood based on Poisson distribution over an 80 by 80 grid and across\n9\n\n--- Page 10 ---\na time series in traditional Bayesian approaches would require heavy computation and becomes\nincreasingly challenging at higher resolutions and longer timescales. Likelihood-free ABC-based\napproaches handle the computational burden through the implementation of low dimensional\nsummary statistics for high-dimensional data structures. Nevertheless, the efficacy of these ap-\nproaches is contingent upon the judicious selection of summary statistics and compatible distance\nmetrics. Automating this selection process has been the subject of an intense study.\nFearnhead and Prangle were among the first to effectively bypass the need for selecting summary\nstatistics in ABC38. They demonstrated that the posterior mean of parameters serves as an op-\ntimal summary statistic under quadratic loss and introduced a regression-based method for its\nestimation. Building on this foundation, Jiang et al.35employed dense neural network layers,\nwhile Akesson et al.36used convolutional neural networks (CNN) to encode the posterior mean\nwithin the hidden layers of their architectures before incorporating it as a summary statistic in\nABC frameworks. Notably, Wang et al.39leveraged a VAE model to automate summary statistic\nselection. Specifically, they derived latent variables ( zsim) from a small sample of simulated data\nand then used a support vector regression model to link \u03b8andzsim, treating the latter as response\nvariables. Predicted zsim\nifor each sampled \u03b8iwere then used for parameter inference.\nOur approach differs fundamentally from the studies described above in its learning objective.\nRather than approximating the posterior mean, viaABC is designed to create regularized and\nmeaningful latent representations while reconstructing the original data. This design philoso-\nphy aligns closely with the manifold hypothesis \u2014the principle that the underlying structure of high\ndimensional data resides within low dimensional manifolds embedded within the high dimen-\nsional space. Moreover, our model architecture provides a key advantage that it can encode and\nanalyze both spatial and temporal information within a single, unified inference framework, lever-\naging the inherent capabilities of the vision transformer. In contrast, the previously described ap-\nproaches are typically designed to handle either spatial or temporal data exclusively. Although\na sequential CNN that first extracts spatial features before modeling temporal dynamics could\ntheoretically achieve comparable results.\nLastly, we demonstrated viaABC\u2019s ability to leverage contextual dependencies beyond spatial con-\ntexts. We showed that viaABC achieved results comparable to established Bayesian algorithms\nwhen estimating parameters of the Lotka-Volterra predator-prey model using sparse, noisy data.\nIn future work, we will expand our framework to enable comparison and ranking of mathematical\nmodels. We propose implementing hierarchical architectures that encode simulations from inde-\npendent models within a single, categorized latent space. The resulting ensemble representations\nof simulated dynamics across all candidate models can, in principle, be leveraged to derive model-\naveraged predictions and compute model weights in conjunction with parameter inference.\n10\n\n--- Page 11 ---\nMethods\nData generation for the SIRS model:\nWe simulated the spatial SIRS model using predefined initial conditions on an 80\u00d780grid, where\neach cell represents an individual. Across all simulations, we chose five infection hotspots within\nthe grid. The model is initialized at t= 0with an infected individual in the vicinity of each infec-\ntion hotspot. The exact locations of initial infections in each simulation was varied stochastically\nby sampling from a uniform distribution over (-5,5) in each direction. Susceptible individuals get\ninfected with the following probability P(Infected |Susceptible ) = 1\u2212e\u2212\u03b2\u00b7i\u00b7\u2206t,where iis the num-\nber of infected neighbors and \u2206tis the simulation time step. An infected individual recovers from\nan infection after a fixed period \u03c4Iand a recovered individual remain resistant to new infection\nfor\u03c4Rtime period, which was fixed to be 1.0. For simulations and inference, we use general priors\nUnif (0,4.3)for both \u03b2and\u03c4I, and set the stepsize \u2206t= 0.05. Generated video is then sliced into\nimages taken at every 20 steps form the training data. We generate the observed data using same\nprocedure at \u03b2and\u03c4I= (1.0,1.0).\nData generation and scaling for the Lotka-Volterra model:\nWe simulated the Lotka-Volterra model using fixed initial conditions of (x, y) = (1 ,0.5). For train-\ning, the parameters aandbwere sampled from uniform priors, a, b\u223cUnif(0,10), using Latin\nHypercube Sampling (LHS). The model was numerically integrated using the RK45 ODE solver in\npython . Variation between data scales in multivariate time series presents optimization challenges\nfor deep learning models. Data normalization is thus a crucial pre-processing step to ensure sta-\nble training. A widely used normalization approach involves applying an affine transformation\nto the time series, i.e.. \u02dcx= (xi\u2212m)/s40,41. We employed mean scaling by setting m= 0 and\ns=1\nnPn\ni=1|xi|for both simulated and observed data generated using the Lotka-Volterra model,\nas it has demonstrated effectiveness in deep learning models frequently applied to practical time-\nseries tasks40\u201342. During inference, parameter values were drawn from the same uniform priors,\nbut without LHS sampling.\nCode availability: Code containing model definitions, training scripts, inference scripts, and note-\nbooks used to generate our figures for reproducibility is available in a GitHub repository archived\non Zenodo: https://zenodo.org/records/15776261 .\n11\n\n--- Page 12 ---\nAlgorithm 1 viaABC: Variational Inference Assisted Approximate Bayesian Computation\n1:Given:\n\u03b6(\u00b7): a trained encoder\nT: total number of iterations for termination\nN: number of accepted particles per iteration\nk: multiplier for the initial sampling pool ( k >1)\nq: final quantile threshold for termination\nzobs: encoded observed data, i.e., zobs=\u03b6(yobs)\nInitialization ( t= 1):\n2:fori= 1tokNdo\n3: Sample: \u03b8(1)\ni\u223c\u03c0(\u03b8)\n4: Simulate: ysim\u223cf(y|\u03b8(1)\ni)\n5: Encode: zsim\ni=\u03b6(ysim)\n6: Compute distance: di=\u03c1(zobs, zsim\ni)\n7:end for\n8:LetD={di}kN\ni=1and sort Din increasing order\n9:Re-order particles {\u03b8(1)\ni}kN\ni=1accordingly to D\n10:Set initial tolerance \u03f51=d(N)(theNth smallest value in D)\n11:Set initial particles: {\u03b8(1)\ni}N\ni=1\nIterations ( 2\u2264t\u2264T):\n12:fort= 2toTdo\n13: Compute weighted empirical variance: \u03c42\nt\u22121= 2\u00b7Var\u03c9\u0010\n{\u03b8(t\u22121)\ni}N\ni=1\u0011\n14: fori= 1toNdo\n15: repeat\n16: Sample \u03b8\u2217\u223c {\u03b8(t\u22121)\nj}N\nj=1with weights {\u03c9(t\u22121)\nj}N\nj=1\n17: Perturb: \u03b8\u2217\u2217\ni\u223c N(\u03b8\u2217, \u03c42\nt\u22121)\n18: Simulate ysim\u223cf(y|\u03b8\u2217\u2217\ni)\n19: Encode: zsim=\u03b6(ysim)\n20: Compute distance: d=\u03c1(zobs, zsim)\n21: until d\u2264\u03f5t\u22121\n22: Record distance: d(t)\ni=d\n23: Record particle: \u03b8(t)\ni=\u03b8\u2217\u2217\n24: Update weight:\n\u03c9(t)\ni\u221d\u03c0(\u03b8(t)\ni)\nPN\nj=1\u03c9(t\u22121)\nj\u00b7\u03d5\u0010\n\u03b8(t)\ni;\u03b8(t\u22121)\nj, \u03c42\nt\u22121\u0011\nwhere \u03d5(\u00b7;\u00b5, \u03c32)is the normal density function\n25: end for\n12\n\n--- Page 13 ---\n26: Normalize weights such thatPN\ni=1w(t)\ni= 1\n27: Estimate normalizing constant:\n\u02c6ct= sup\n\u03b8\u03c0\u03f5t(\u03b8)\n\u03c0\u03f5t\u22121(\u03b8)\n28: Update quantile level: qt=1\n\u02c6ct\n29: Update tolerance: \u03f5t=Quantile ({d(t)\ni}N\ni=1, qt)\n30: ifqt\u2265qthen\n31: Break\n32: end if\n33:end for\nCited literature\n1. Donald B. Rubin. Bayesianly justifiable and relevant frequency calculations for the applied\nstatistician. The Annals of Statistics , 12(4), December 1984.\n2. Peter J. Diggle and Richard J. Gratton. Monte carlo methods of inference for implicit statistical\nmodels. Journal of the Royal Statistical Society. Series B (Methodological) , 46(2):193\u2013227, 1984.\n3. Simon Tavar \u00b4e, David J Balding, Robert C Griffiths, and Peter Donnelly. Inferring coalescence\ntimes from dna sequence data. Genetics , 145(2):505\u2013518, 1997.\n4. S. A. Sisson, Y. Fan, and Mark M. Tanaka. Sequential monte carlo without likelihoods. Pro-\nceedings of the National Academy of Sciences , 104(6):1760\u20131765, February 2007.\n5. Paul Marjoram, John Molitor, Vincent Plagnol, and Simon Tavar \u00b4e. Markov chain monte carlo\nwithout likelihoods. Proceedings of the National Academy of Sciences , 100(26):15324\u201315328, 2003.\n6. Tina Toni, David Welch, Natalja Strelkowa, Andreas Ipsen, and Michael PH Stumpf. Approxi-\nmate bayesian computation scheme for parameter inference and model selection in dynamical\nsystems. Journal of the Royal Society Interface , 6(31):187\u2013202, 2009.\n7. Christian P Robert, Mark A Beaumont, Jean-Michel Marin, and Jean-Marie Cornuet. Adaptiv-\nity for abc algorithms: the abc-pmc scheme. arXiv preprint arXiv:0805.2256 , 2008.\n8. Noel Cressie, Matthew Sainsbury-Dale, and Andrew Zammit-Mangion. Basis-function mod-\nels in spatial statistics. Annual Review of Statistics and Its Application , 9(1):373\u2013400, March 2022.\n9. Emily L. Kang and Noel Cressie. Bayesian inference for the spatial random effects model.\nJournal of the American Statistical Association , 106(495):972\u2013983, September 2011.\n10. Wentao Zhan and Abhirup Datta. Neural networks for geospatial data. Journal of the American\nStatistical Association , 120(549):535\u2013547, June 2024.\n13\n\n--- Page 14 ---\n11. Arkajyoti Saha, Sumanta Basu, and Abhirup Datta. Random forests for spatially dependent\ndata. Journal of the American Statistical Association , 118(541):665\u2013683, August 2021.\n12. Abhirup Datta, Sudipto Banerjee, Andrew O. Finley, and Alan E. Gelfand. Hierarchical\nnearest-neighbor gaussian process models for large geostatistical datasets. Journal of the Amer-\nican Statistical Association , 111(514):800\u2013812, April 2016.\n13. Oliver Hamelijnck, William J. Wilkinson, Niki A. Loppi, Arno Solin, and Theodoros\nDamoulas. Spatio-temporal variational gaussian processes. 11 2021.\n14. Grant D. Brown, Aaron T. Porter, Jacob J. Oleson, and Jessica A. Hinman. Approximate\nbayesian computation for spatial seir(s) epidemic models. Spatial and Spatio-temporal Epidemi-\nology , 24:27\u201337, February 2018.\n15. La \u00b4\u0131s Picinini Freitas, Alexandra M. Schmidt, William Cossich, Oswaldo Gonc \u00b8alves Cruz, and\nMarilia S \u00b4a Carvalho. Spatio-temporal modelling of the first chikungunya epidemic in an\nintra-urban setting: The role of socioeconomic status, environment and temperature. PLOS\nNeglected Tropical Diseases , 15(6):e0009537, June 2021.\n16. Jifan Li, Edward L. Ionides, Aaron A. King, Mercedes Pascual, and Ning Ning. Inference on\nspatiotemporal dynamics for networks of biological populations. 11 2023.\n17. Umberto Simola, Jessi Cisewski-Kehe, Michael U Gutmann, and Jukka Corander. Adaptive\napproximate bayesian computation tolerance selection. Bayesian analysis , 16(2):397\u2013423, 2021.\n18. Sen Pei, Sasikiran Kandula, Wan Yang, and Jeffrey Shaman. Forecasting the spatial trans-\nmission of influenza in the united states. Proceedings of the National Academy of Sciences ,\n115(11):2752\u20132757, February 2018.\n19. Zhibin Shi, Lili Wei, Pengfei Wang, Shida Wang, Zaisi Liu, Yongping Jiang, and Jingfei Wang.\nSpatio-temporal spread and evolution of influenza a (h7n9) viruses. Frontiers in Microbiology ,\n13, September 2022.\n20. Hawre Jalal, Kyueun Lee, and Donald S. Burke. Oscillating spatiotemporal patterns of covid-\n19 in the united states. Scientific Reports , 14(1), September 2024.\n21. W. O. Kermack and A. G. McKendrick. A contribution to the mathematical theory of epi-\ndemics. Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical\nand Physical Character , 115(772):700\u2013721, 1927.\n22. W. Marijn van Ballegooijen and Maarten C. Boerlijst. Emergent trade-offs and selection\nfor outbreak frequency in spatial epidemics. Proceedings of the National Academy of Sciences ,\n101(52):18246\u201318250, December 2004.\n23. Roy M Anderson and Robert M May. Infectious Diseases of Humans: Dynamics and Control .\nOxford University Press, 05 1991.\n14\n\n--- Page 15 ---\n24. Christoph Feichtenhofer, Yanghao Li, Kaiming He, et al. Masked autoencoders as spatiotem-\nporal learners. Advances in neural information processing systems , 35:35946\u201335958, 2022.\n25. Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew\nBotvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual con-\ncepts with a constrained variational framework. In International conference on learning represen-\ntations , 2017.\n26. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of\ndeep bidirectional transformers for language understanding. In Proceedings of the 2019 confer-\nence of the North American chapter of the association for computational linguistics: human language\ntechnologies, volume 1 (long and short papers) , pages 4171\u20134186, 2019.\n27. Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll \u00b4ar, and Ross Girshick. Masked\nautoencoders are scalable vision learners. 11 2021.\n28. Zhan Tong, Yibing Song, Jue Wang, and Limin Wang. Videomae: Masked autoencoders are\ndata-efficient learners for self-supervised video pre-training. 03 2022.\n29. Michael D McKay, Richard J Beckman, and William J Conover. A comparison of three meth-\nods for selecting values of input variables in the analysis of output from a computer code.\nTechnometrics , 42(1):55\u201361, 2000.\n30. Jean-Michel Marin, Pierre Pudlo, Christian P Robert, and Robin J Ryder. Approximate\nbayesian computational methods. Statistics and computing , 22(6):1167\u20131180, 2012.\n31. Alfred James Lotka. Elements of physical biology . Williams & Wilkins, 1925.\n32. Vito Volterra. Variations and fluctuations of the number of individuals in animal species living\ntogether. ICES Journal of Marine Science , 3(1):3\u201351, 1928.\n33. Dennis Prangle. Adapting the abc distance function. 2017.\n34. Khanh N Dinh, Zijin Xiang, Zhihan Liu, and Simon Tavar \u00b4e. Approximate bayesian computa-\ntion sequential monte carlo via random forests. arXiv preprint arXiv:2406.15865 , 2024.\n35. Bai Jiang, Tung-Yu Wu, Charles Zheng, and Wing H. Wong. Learning summary statistic for\napproximate bayesian computation via deep neural network. Statistica Sinica , 27(4):1595\u20131618,\n2017.\n36. Mattias \u02daAkesson, Prashant Singh, Fredrik Wrede, and Andreas Hellander. Convolutional neu-\nral networks as summary statistics for approximate bayesian computation. IEEE/ACM Trans-\nactions on Computational Biology and Bioinformatics , 19(6):3353\u20133365, 2021.\n37. Meili Baragatti, Casenave C \u00b4eline, Bertrand Cloez, David M \u00b4etivier, and Isabelle Sanchez. Ap-\nproximate bayesian computation with deep learning and conformal prediction. 06 2024.\n15\n\n--- Page 16 ---\n38. Paul Fearnhead and Dennis Prangle. Constructing summary statistics for approximate\nbayesian computation: Semi-automatic approximate bayesian computation. Journal of the\nRoyal Statistical Society Series B: Statistical Methodology , 74(3):419\u2013474, 05 2012.\n39. Jiaquan Wang, Yang Zeng, Xinchao Jiang, Hu Wang, Enying Li, and Guangyao Li. Variational\nauto-encoder based approximate bayesian computation uncertian inverse method for sheet\nmetal forming problem. 07 2019.\n40. Stephan Rabanser, Tim Januschowski, Valentin Flunkert, David Salinas, and Jan Gasthaus.\nThe effectiveness of discretization in forecasting: An empirical study on neural time series\nmodels. arXiv preprint arXiv:2005.10111 , 2020.\n41. Abdul Fatir Ansari, Lorenzo Stella, Caner Turkmen, Xiyuan Zhang, Pedro Mercado, Huibin\nShen, Oleksandr Shchur, Syama Rangapuram, Sebastian Pineda Arango, Shubham Kapoor,\net al. Chronos: Learning the language of time series. 2024.\n42. David Salinas, Valentin Flunkert, Jan Gasthaus, and Tim Januschowski. Deepar: Proba-\nbilistic forecasting with autoregressive recurrent networks. International journal of forecasting ,\n36(3):1181\u20131191, 2020.\n16\n\n--- Page 17 ---\nSupplementary Information\nUnmasked Masked\n510 150123\n510 150123\n510 150246\n510 150246\nPrey\nPredator\nTimeReconstrution of the tr aining data\nFigure S1: Masking Approach for the Lotka-Volterra model. Comparison of reconstructions from masked and un-\nmasked inputs. Four randomly selected training samples are shown, with masked inputs in the first row and unmasked\ninputs in the second row. For each sample, \u224815% of the data is masked at random ( i.e.2 data points) of the input is\nmasked. Green bars indicate the positions of the masked data points. Lines represent the reconstructions of the original\ninput shown as black dots.\n17\n\n--- Page 18 ---\n0.8 1.0 1.2 1.4 1.6\na0.000.050.100.150.20Proportion\n1.0 1.5 2.0\nb0.0000.0250.0500.0750.1000.1250.1500.175A\n0 2 4 6 8 10 12 14\nTime0.51.01.52.02.53.0 PopulationPrey population\n0 2 4 6 8 10 12 14\nTime0.00.51.01.52.02.5Predator populationBFigure S2: Inferring predator-prey dynamics using MCMC. A. Posterior distribution of parameters aandbusing 1,000\naccepted particles from MCMC for the Lotka-Volterra system. B.Predicted predator-prey dynamics with 95% credible\nintervals (shaded), and median trajectories (solid lines). Black dashed lines represent the ground truth dynamics.\n18",
  "project_dir": "artifacts/projects/Spatiodynamic Inference using Vision-Based Generative Modeling",
  "communication_dir": "artifacts/projects/Spatiodynamic Inference using Vision-Based Generative Modeling/.agent_comm",
  "assigned_at": "2025-08-03T20:55:35.586264",
  "status": "assigned"
}